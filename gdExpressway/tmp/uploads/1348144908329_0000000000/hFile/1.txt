A distributed realtiem computation system 
Storm的作者说让 Hadoop 模拟实时计算的工具是 Storm。我写 Storm 的目的是让 Hadoop 可以健壮、可扩展地处理大量的实时数据。Storm 在数据流上运行无限的计算，并且对这些数据处理提供了强有力的保障。

Spout 和 bolt 都各有接口，你需要实现他们来执行你的应用程序的逻辑。

Hadoop job will be finished,topology will run forever
什么叫持续的数据流

　　它是以连续或者间隔的方式，通过推送或采集的形式到达的数据。里面有两个纬度：可以连续、源源不断的，可以批量的方式推断。获取可以推送也可以采取的方式。系统日志是一直在增长中，常见的有搜索日志等。内容有新闻、上传图片、文字信息、视频信息，很多以持续信息流出现的，不断被采集到数据分析引擎里面，其他E-mail、短信、微博也是持续的数据流，在不停地产生中，如果进行大型的分析处理的话，要持续分析处理。

　　今天的互联网当中，如果说是数据驱动的互联网，持续的数据流占绝大部分的比例，或者最重要的一些数据。

持续数据流有那些场景?

　　搜索内容广告精细匹配和排序。无论是网页搜索还是传统型的广告，包括内容推荐都需要对持续的用户行为的日志进行分析，甚至对其他的对用户社交的更新进行分析。

　　用户行为分析和建模，我负责雅虎个性化搜索平台，通过用户在互联网上，包括雅虎和雅虎以外各种用户行为分析，对用户行为进行建模，进行个性化的操作。

　　媒体内容处理分析，刚才提到对文章的过滤、对文章自然语言的分析，对视频的分析，对视频过滤导波视频检测。

　　社交网络分析，对社交网络相关关联性的关系分析。基本涵盖了绝大多数的热点行业。


增量计算。我们做日志分析，总是增量出现，很难用全量的方式计算。增量计算在很多时候确实能够带来效率的提升。如果需要重复的计算，每次把数据计算一遍肯定会浪费。我们能够应用简化增量过程。


例如emit方法经过不同的重载（C++叫重载函数，这里一时不知道术语是什么，意思就是参数不同，不同实现）
1、_collector.emit(tuple,new Values(word));
2、_collector.emit(new Values(word));
代码一中的第一个参数tuple是将要发射新tuple的父tuple，new Values(word)是新的tuple。这句代码就是将新的tuple与它的父tuple绑定一起，那么如果新的tuple出错，那么父tuple也会被重新处理。
代码2则脱离了父tuple也即脱离了原来的tuple树，那么如果新的tuple出错，则父tuple也不会被重新处理。
而选择哪种方案是由用户选择。
此篇东西让我对一个处理错误的机制由思想到具体每个方法的实现有了些认识。

Hadoop是一台大型“机器”，当启动并全速运转时处理数据的性能惊人，你唯一需要操心的就是硬盘的传输速度跟不上。但是每次你准备启动分析数据时，都需要把所有的数据都过一遍，当数据集越来越庞大时，这个问题将导致分析时间无限延长。
那么Google是如何解决让搜索结果返回速度越来越接近实时的呢？答案是用增量处理引擎Percolator代替GMR。通过只处理新增的、改动过的或删除的文档和使用二级指数来高效率建目录，返回查询结果。Percolator论文的作者写道：“将索引系统转换成增量系统…将文档处理延迟缩短了100倍。”这意味着索引web新内容的速度比用MapReduce快100倍！
